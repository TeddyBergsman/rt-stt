# Improving RT-STT Accuracy Guide

## Current Issues with Base Model

Your test revealed several accuracy problems:
- **Poor transcription quality**: Lots of hallucinations and repetitions
- **High latency**: Average 9.4 seconds (unacceptable for real-time)
- **Name recognition**: Struggled with "Teddy Bergsman" (though got it once!)
- **Word confusion**: "testing" â†’ "wasting", "wanting", etc.

## Root Cause

The **base.en model (142 MB)** is too small for accurate real-time transcription. It was designed for speed over accuracy.

## Solutions

### 1. Upgrade to Better Models

Download better models:
```bash
./download_better_models.sh
```

This downloads:
- **small.en (466 MB)**: 3x larger, much better accuracy
- **medium.en (1.5 GB)**: 10x larger, best accuracy for real-time

### 2. Test with Better Models

```bash
# Good balance of speed and accuracy
./improve_accuracy.sh

# Or explicitly:
./test_clean.sh --model models/ggml-small.en.bin

# Best accuracy (may be slower)
./test_clean.sh --model models/ggml-medium.en.bin
```

### 3. Expected Improvements

With **small.en model**:
- Better word recognition (no more "one mistake")
- Proper name detection
- Reduced hallucinations
- Latency: ~1-2 seconds

With **medium.en model**:
- Near-perfect accuracy
- Excellent with names and technical terms
- Minimal errors
- Latency: ~2-3 seconds

### 4. Additional Optimizations

For your M4 Pro, you can also:

1. **Convert to Core ML** (30-50% faster):
   ```bash
   cd third_party/whisper.cpp
   ./models/generate-coreml-model.sh ../../models/ggml-small.en.bin
   ```

2. **Fine-tune VAD settings** in `test_main.cpp`:
   - Lower energy threshold for sensitive mics
   - Adjust speech end delay

3. **Optimize audio buffer**:
   - Smaller chunks for lower latency
   - Larger chunks for better context

### 5. Hardware Considerations

Your M4 Pro with Metal acceleration can easily handle:
- **small.en**: Real-time with <1s latency
- **medium.en**: Real-time with ~2s latency
- **large**: May struggle with real-time

### 6. Quick Comparison

| Model | Size | Accuracy | Latency | Use Case |
|-------|------|----------|---------|----------|
| tiny.en | 39 MB | Poor | <0.5s | Commands only |
| base.en | 142 MB | Fair | ~1s | Simple dictation |
| small.en | 466 MB | Good | ~1.5s | **Recommended** |
| medium.en | 1.5 GB | Excellent | ~2.5s | Professional use |
| large | 3.1 GB | Best | >4s | Offline processing |

## Next Steps

1. Download better models: `./download_better_models.sh`
2. Test with small model: `./improve_accuracy.sh`
3. Compare results with your original test phrase
4. If latency is acceptable, try medium model for even better accuracy

The small.en model should give you a dramatic improvement in transcription quality while maintaining reasonable real-time performance on your M4 Pro.
